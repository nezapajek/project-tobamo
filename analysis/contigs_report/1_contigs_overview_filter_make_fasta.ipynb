{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d069ec",
   "metadata": {},
   "source": [
    "#### steps overview:\n",
    "0. import packages and data (Snakemake final output table)\n",
    "1. remove control SRRs (keep only selected 253 SRRs (config/samples_test.tsv))\n",
    "2. check for duplicated contigs (same study, different SRA entries), keep only one copy (with better metadata)\n",
    "3. remove cellular organisms as per megan taxonomy\n",
    "4. check numbers\n",
    "5. make fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "424853b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e511721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Snakemake final output\n",
    "df = pd.read_csv('/home/tobamo/analize/project-tobamo/results/megan6_results_combined.csv', index_col=0)\n",
    "# import selected samples list\n",
    "samples_path = '/home/tobamo/analize/project-tobamo/config/samples_test.tsv' #253 selected SRRs\n",
    "with open(samples_path) as file: samples = [line.strip() for line in file.readlines()][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b219c5b",
   "metadata": {},
   "source": [
    "1. remove control SRRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30ec8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove control contigs, keep only selected samples\n",
    "test_results = df[df['SRR'].isin(samples)] # filter the main DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633567d",
   "metadata": {},
   "source": [
    "2. check for duplicated contigs (same study, different SRA entries), keep only one copy (with better metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c687de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences shared by multiple qseqid: 15\n",
      "Number of qseqid involved: 31\n",
      "qseqid involved in duplicated sequences:\n",
      "{'NODE_138_length_1097_cov_1637.345361_ERR2737479', 'NODE_4862_length_2337_cov_106.419807_SRR5087400', 'NODE_244_length_5617_cov_62.071480_SRR8749695', 'NODE_228_length_845_cov_1276.600279_ERR2737479', 'NODE_263_length_789_cov_170.131420_ERR2737479', 'NODE_244_length_5617_cov_62.071480_SRR8658357', 'NODE_82_length_1552_cov_1.965614_ERR2737479', 'NODE_14_length_5191_cov_521.552923_ERR2737479', 'NODE_316_length_714_cov_3.042589_ERR3179625', 'NODE_323_length_705_cov_6047.968858_ERR2737479', 'NODE_251_length_6673_cov_596.344603_SRR8658359', 'NODE_263_length_789_cov_170.131420_ERR3179625', 'NODE_83_length_1545_cov_832.384344_ERR2737479', 'NODE_121_length_1179_cov_560.262357_ERR3179625', 'NODE_80_length_1581_cov_92.495186_ERR2737479', 'NODE_4542_length_2337_cov_155.333041_SRR5087405', 'NODE_121_length_1179_cov_560.262357_ERR2737479', 'NODE_186_length_6730_cov_324.596573_SRR8658358', 'NODE_316_length_714_cov_3.042589_ERR2737479', 'NODE_14_length_5191_cov_521.552923_ERR3179625', 'NODE_80_length_1581_cov_92.495186_ERR3179625', 'NODE_186_length_6730_cov_324.596573_SRR8749694', 'NODE_242_length_5620_cov_498.148836_SRR8749695', 'NODE_138_length_1097_cov_1637.345361_ERR3179625', 'NODE_83_length_1545_cov_832.384344_ERR3179625', 'NODE_323_length_705_cov_6047.968858_ERR3179625', 'NODE_251_length_6673_cov_596.344603_SRR8749693', 'NODE_82_length_1552_cov_1.965614_ERR3179625', 'NODE_4269_length_2337_cov_77.980719_SRR6233765', 'NODE_228_length_845_cov_1276.600279_ERR3179625', 'NODE_242_length_5620_cov_498.148836_SRR8658357'}\n",
      "SRRs with duplicated qseqids:\n",
      "['ERR2737479' 'ERR3179625' 'SRR5087400' 'SRR5087405' 'SRR6233765'\n",
      " 'SRR8658357' 'SRR8658358' 'SRR8658359' 'SRR8749693' 'SRR8749694'\n",
      " 'SRR8749695']\n"
     ]
    }
   ],
   "source": [
    "# Group by sequence and collect unique qseqid values for each sequence\n",
    "seq_to_qseqid = test_results.groupby('sequence')['qseqid'].unique()\n",
    "\n",
    "# Find sequences that are associated with more than one unique qseqid\n",
    "duplicated_seqs = seq_to_qseqid[seq_to_qseqid.apply(len) > 1]\n",
    "\n",
    "# Get all qseqid values involved in duplicated sequences\n",
    "duplicated_qseqids = set(qseqid for qseqids in duplicated_seqs for qseqid in qseqids)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of sequences shared by multiple qseqid: {len(duplicated_seqs)}\")\n",
    "print(f\"Number of qseqid involved: {len(duplicated_qseqids)}\")\n",
    "print(\"qseqid involved in duplicated sequences:\")\n",
    "print(duplicated_qseqids)\n",
    "print('SRRs with duplicated qseqids:')\n",
    "print(f\"{test_results[test_results['qseqid'].isin(duplicated_qseqids)].SRR.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62289d",
   "metadata": {},
   "source": [
    "! manual inspection (look it up online or get metadata from SRAweb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08e6c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after manual metadata inspection, remove duplicated SRRs (same study, different SRA entries), keep only one copy (with better metadata)\n",
    "SRRs_to_remove = ['ERR2737479', 'SRR8749694', 'SRR8749695', 'SRR8749695', 'SRR8749693', 'SRR5087405', 'SRR6233765']\n",
    "\n",
    "# remove SRRs\n",
    "test_results_deduplicated = test_results[~test_results['SRR'].isin(SRRs_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb44c9d",
   "metadata": {},
   "source": [
    "3. remove cellular organisms as per megan taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccdb9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many contigs have 'cellular' in megan taxonomy\n",
    "test_results_non_cellular = test_results_deduplicated[~test_results_deduplicated['megan_tax'].str.contains('cellular')]\n",
    "test_results_cellular = test_results_deduplicated[test_results_deduplicated['megan_tax'].str.contains('cellular')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c311a4",
   "metadata": {},
   "source": [
    "4. Remove problematic SRR6846476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2401ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove problematic Singapore contigs from SRR6846476\n",
    "test_results_non_cellular_filtered = test_results_non_cellular[~(test_results_non_cellular['SRR'] == 'SRR6846476')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eeed56",
   "metadata": {},
   "source": [
    "check numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59faf999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contig counts report:\n",
      "1. All contigs: 3406\n",
      "2. After removing control SRRs: 2567\n",
      "3. After removing duplicated SRRs: 2549\n",
      "4A. Non-cellular contigs: 2383\n",
      "4B. Cellular contigs: 166\n",
      "5. Non-cellular without problematic SRR6846476: 510\n"
     ]
    }
   ],
   "source": [
    "print(\"Contig counts report:\")\n",
    "print(f\"1. All contigs: {df.qseqid.nunique()}\")\n",
    "print(f\"2. After removing control SRRs: {test_results.qseqid.nunique()}\")\n",
    "print(f\"3. After removing duplicated SRRs: {test_results_deduplicated.qseqid.nunique()}\")\n",
    "print(f\"4A. Non-cellular contigs: {test_results_non_cellular.qseqid.nunique()}\")\n",
    "print(f\"4B. Cellular contigs: {test_results_cellular.qseqid.nunique()}\")\n",
    "print(f\"5. Non-cellular without problematic SRR6846476: {test_results_non_cellular_filtered.qseqid.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93f9b58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_non_cellular_filtered.qseqid.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7815a79",
   "metadata": {},
   "source": [
    "5. make fasta files and .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e4f7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dict from from qseqid and sequence\n",
    "contigs_all = dict(df.filter(['qseqid', 'sequence']).values) # all contigs\n",
    "contigs_all_test = dict(test_results.filter(['qseqid', 'sequence']).values) # test contigs (removed control SRRs)\n",
    "contigs_all_deduplicated = dict(test_results_deduplicated.filter(['qseqid', 'sequence']).values) # deduplicated contigs\n",
    "contigs_non_cellular = dict(test_results_non_cellular.filter(['qseqid', 'sequence']).values) # non-cellular contigs\n",
    "contigs_non_cellular_filtered = dict(test_results_non_cellular_filtered.filter(['qseqid', 'sequence']).values) # non-cellular without problematic SRR6846476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3885363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for writing fasta from a dictionary\n",
    "def write_fasta(seq_dict, output_file):\n",
    "    with open(output_file, 'w') as o:\n",
    "        for key, val in seq_dict.items():\n",
    "            o.write('>' + key + '\\n')\n",
    "            o.write(val + '\\n')\n",
    "    return output_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a26c2637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ../data/contigs/contigs_all.fasta\n",
      "Wrote ../data/contigs/contigs_all_test.fasta\n",
      "Wrote ../data/contigs/contigs_all_deduplicated.fasta\n",
      "Wrote ../data/contigs/contigs_non_cellular.fasta\n",
      "Wrote ../data/contigs/contigs_non_cellular_filtered.fasta\n"
     ]
    }
   ],
   "source": [
    "# make fasta files, skip if file already exists\n",
    "path = '../data/contigs/'\n",
    "\n",
    "for seq_dict, output_file in [\n",
    "    (contigs_all, f'{path}contigs_all.fasta'),\n",
    "    (contigs_all_test, f'{path}contigs_all_test.fasta'),\n",
    "    (contigs_all_deduplicated, f'{path}contigs_all_deduplicated.fasta'),\n",
    "    (contigs_non_cellular, f'{path}contigs_non_cellular.fasta'),\n",
    "    (contigs_non_cellular_filtered, f'{path}contigs_non_cellular_filtered.fasta'),\n",
    "]:\n",
    "    write_fasta(seq_dict, output_file)\n",
    "    print(f\"Wrote {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobamo-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
