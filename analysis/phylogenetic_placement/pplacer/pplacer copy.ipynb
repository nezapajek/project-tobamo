{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b2386a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b80619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contigs = SeqIO.to_dict(SeqIO.parse(\"/home/tobamo/analize/project-tobamo/analysis/data/contigs/contigs_non_cellular_filtered.fasta\", \"fasta\"))\n",
    "gt = pd.read_excel(\"/home/tobamo/analize/project-tobamo/analysis/data/domain_sci_input/ground_truth_final_added_categories.xlsx\")\n",
    "\n",
    "novel_tobamo = gt[gt[\"category\"] == \"tob2\"][\"contig_name\"].tolist()\n",
    "tob2_contigs = [contig for k,contig in contigs.items() if contig.id in novel_tobamo]\n",
    "\n",
    "os.makedirs(\"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/\", exist_ok=True)\n",
    "SeqIO.write(tob2_contigs, \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_contigs.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d760a",
   "metadata": {},
   "source": [
    "# Pplacer Implementation for Tobamovirus Analysis\n",
    "\n",
    "This notebook implements phylogenetic placement using pplacer to analyze novel tobamovirus contigs (`tob2_contigs`) against a reference phylogeny.\n",
    "\n",
    "## Overview\n",
    "Pplacer places query sequences on a fixed reference phylogenetic tree according to a reference alignment. It finds the optimal attachment location and pendant branch length that maximize the likelihood.\n",
    "\n",
    "## Workflow Steps:\n",
    "1. Install pplacer and dependencies\n",
    "2. Prepare reference sequences and alignment\n",
    "3. Build reference tree\n",
    "4. Create reference package\n",
    "5. Run pplacer on tob2_contigs\n",
    "6. Analyze results with guppy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0172793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pplacer available: False\n",
      "guppy available: False\n",
      "\n",
      "Placer suite not found. Installing via conda...\n",
      "Installing pplacer via conda...\n",
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 25.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.9.1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/tobamo/miniconda3/envs/tobamo-model\n",
      "\n",
      "  added / updated specs:\n",
      "    - pplacer\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2025.10.5  |       hbd8a1cb_0         152 KB  conda-forge\n",
      "    openssl-3.5.4              |       h26f9b46_0         3.0 MB  conda-forge\n",
      "    pplacer-1.1.alpha19        |       h9ee0642_2         8.6 MB  bioconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  pplacer            bioconda/linux-64::pplacer-1.1.alpha19-h9ee0642_2 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                       2025.8.3-hbd8a1cb_0 --> 2025.10.5-hbd8a1cb_0 \n",
      "  openssl                                  3.5.3-h26f9b46_1 --> 3.5.4-h26f9b46_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ca-certificates-2025 | 152 KB    |            |   0% \n",
      "pplacer-1.1.alpha19  | 8.6 MB    |            |   0% \u001b[A\n",
      "\n",
      "openssl-3.5.4        | 3.0 MB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "ca-certificates-2025 | 152 KB    | #          |  11% \u001b[A\u001b[A\n",
      "ca-certificates-2025 | 152 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "openssl-3.5.4        | 3.0 MB    | ######7    |  68% \u001b[A\u001b[A\n",
      "pplacer-1.1.alpha19  | 8.6 MB    | ##5        |  26% \u001b[A\n",
      "pplacer-1.1.alpha19  | 8.6 MB    | ######5    |  65% \u001b[A\n",
      "pplacer-1.1.alpha19  | 8.6 MB    | #########9 |  99% \u001b[A\n",
      "\n",
      "openssl-3.5.4        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "                                                     \u001b[A\n",
      "                                                     \u001b[A\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "# Check pplacer installation and install if needed\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def check_command(cmd):\n",
    "    \"\"\"Check if a command is available\"\"\"\n",
    "    try:\n",
    "        subprocess.run(cmd, capture_output=True, check=True)\n",
    "        return True\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        return False\n",
    "\n",
    "# Check if pplacer and guppy are available\n",
    "pplacer_available = check_command(['pplacer', '--version'])\n",
    "guppy_available = check_command(['guppy', '--version'])\n",
    "\n",
    "print(f\"pplacer available: {pplacer_available}\")\n",
    "print(f\"guppy available: {guppy_available}\")\n",
    "\n",
    "if not pplacer_available or not guppy_available:\n",
    "    print(\"\\nPlacer suite not found. Installing via conda...\")\n",
    "    # Check if conda is available\n",
    "    conda_available = check_command(['conda', '--version'])\n",
    "    if conda_available:\n",
    "        print(\"Installing pplacer via conda...\")\n",
    "        subprocess.run(['conda', 'install', '-c', 'bioconda', 'pplacer', '-y'], check=True)\n",
    "    else:\n",
    "        print(\"Conda not available. Please install pplacer manually:\")\n",
    "        print(\"1. Download from: https://github.com/matsen/pplacer/releases/latest\")\n",
    "        print(\"2. Or use conda: conda install -c bioconda pplacer\")\n",
    "        print(\"3. Or build from source following: https://matsen.github.io/pplacer/compiling.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0475d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mafft is available\n",
      "FastTree not found. Installing FastTree...\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 25.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.9.1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/tobamo/miniconda3/envs/tobamo-model\n",
      "\n",
      "  added / updated specs:\n",
      "    - fasttree\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    fasttree-2.2.0             |       h7b50bb2_0         200 KB  bioconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         200 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  fasttree           bioconda/linux-64::fasttree-2.2.0-h7b50bb2_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "                                                     \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "All required tools are available!\n"
     ]
    }
   ],
   "source": [
    "# Check if we need additional software for alignment and tree building\n",
    "# We'll need MAFFT for alignment and FastTree for phylogeny\n",
    "\n",
    "def install_if_missing(cmd, package_name, conda_package=None):\n",
    "    \"\"\"Install package if command not found\"\"\"\n",
    "    if not check_command([cmd, '--version']):\n",
    "        print(f\"{cmd} not found. Installing {package_name}...\")\n",
    "        if conda_package and check_command(['conda', '--version']):\n",
    "            subprocess.run(['conda', 'install', '-c', 'bioconda', conda_package, '-y'], check=True)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Please install {package_name} manually\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"{cmd} is available\")\n",
    "        return True\n",
    "\n",
    "# Check and install required tools\n",
    "mafft_ok = install_if_missing('mafft', 'MAFFT', 'mafft')\n",
    "fasttree_ok = install_if_missing('FastTree', 'FastTree', 'fasttree')\n",
    "\n",
    "if mafft_ok and fasttree_ok:\n",
    "    print(\"All required tools are available!\")\n",
    "else:\n",
    "    print(\"Some tools are missing. Please install them manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c834508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating multiple sequence alignment of reference sequences...\n",
      "Running MAFFT: mafft --auto --adjustdirection --thread 4 /home/tobamo/analize/project-tobamo/analysis/data/tobamo/reference_nukleotidne.fasta\n",
      "Alignment completed successfully!\n",
      "Alignment saved to: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta\n",
      "Aligned 125 sequences\n",
      "Alignment length: 14162 positions\n"
     ]
    }
   ],
   "source": [
    "# Create multiple sequence alignment of reference sequences\n",
    "import tempfile\n",
    "\n",
    "print(\"Creating multiple sequence alignment of reference sequences...\")\n",
    "\n",
    "# Paths\n",
    "ref_fasta = \"/home/tobamo/analize/project-tobamo/analysis/data/tobamo/reference_nukleotidne.fasta\"\n",
    "ref_alignment = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta\"\n",
    "\n",
    "# Run MAFFT alignment\n",
    "mafft_cmd = [\n",
    "    'mafft', \n",
    "    '--auto',           # Automatically select strategy\n",
    "    '--adjustdirection', # Reverse complement if needed\n",
    "    '--thread', '4',    # Use 4 threads\n",
    "    ref_fasta\n",
    "]\n",
    "\n",
    "print(f\"Running MAFFT: {' '.join(mafft_cmd)}\")\n",
    "try:\n",
    "    with open(ref_alignment, 'w') as outfile:\n",
    "        result = subprocess.run(mafft_cmd, stdout=outfile, stderr=subprocess.PIPE, text=True, check=True)\n",
    "    print(f\"Alignment completed successfully!\")\n",
    "    print(f\"Alignment saved to: {ref_alignment}\")\n",
    "    \n",
    "    # Check alignment\n",
    "    aligned_seqs = list(SeqIO.parse(ref_alignment, \"fasta\"))\n",
    "    if aligned_seqs:\n",
    "        print(f\"Aligned {len(aligned_seqs)} sequences\")\n",
    "        print(f\"Alignment length: {len(aligned_seqs[0].seq)} positions\")\n",
    "    else:\n",
    "        print(\"Warning: No sequences in alignment file\")\n",
    "        \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"MAFFT failed with error: {e}\")\n",
    "    print(f\"stderr: {e.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10df4ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building reference phylogenetic tree...\n",
      "FastTree has compatibility issues on this system\n",
      "Using IQ-TREE (will run pplacer without stats file)\n",
      "Running IQ-TREE: iqtree -s /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta -m GTR+G --prefix /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree --redo -T 4 -quiet\n",
      "✓ Tree file renamed from /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.treefile to /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre\n",
      "✓ Tree building completed successfully!\n",
      "✓ Tree saved to: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre\n",
      "Tree length: 13965 characters\n",
      "Tree preview: (X03854.1_Barley_stripe_mosaic_virus__BSMV__Type_strain__genomic_RNA_beta:0.7906205365,(((((((((((X1...\n",
      "\n",
      "✅ Tree ready: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre (13,966 bytes)\n",
      "Strategy: Run pplacer without stats file (it will estimate GTR parameters)\n",
      "\n",
      "Note: pplacer should work without stats files by estimating parameters\n",
      "✓ Tree file renamed from /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.treefile to /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre\n",
      "✓ Tree building completed successfully!\n",
      "✓ Tree saved to: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre\n",
      "Tree length: 13965 characters\n",
      "Tree preview: (X03854.1_Barley_stripe_mosaic_virus__BSMV__Type_strain__genomic_RNA_beta:0.7906205365,(((((((((((X1...\n",
      "\n",
      "✅ Tree ready: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre (13,966 bytes)\n",
      "Strategy: Run pplacer without stats file (it will estimate GTR parameters)\n",
      "\n",
      "Note: pplacer should work without stats files by estimating parameters\n"
     ]
    }
   ],
   "source": [
    "# Build reference phylogenetic tree - use working IQ-TREE, then try pplacer without stats\n",
    "print(\"Building reference phylogenetic tree...\")\n",
    "\n",
    "ref_alignment = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta\"\n",
    "ref_tree = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre\"\n",
    "iqtree_prefix = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree\"\n",
    "\n",
    "print(\"FastTree has compatibility issues on this system\")\n",
    "print(\"Using IQ-TREE (will run pplacer without stats file)\")\n",
    "\n",
    "# IQ-TREE command with --redo to overwrite existing files\n",
    "iqtree_cmd = [\n",
    "    'iqtree',\n",
    "    '-s', ref_alignment,     # Input alignment\n",
    "    '-m', 'GTR+G',          # GTR model \n",
    "    '--prefix', iqtree_prefix,  # Output prefix\n",
    "    '--redo',               # Overwrite existing analysis\n",
    "    '-T', '4',              # Use 4 threads\n",
    "    '-quiet'                # Reduce output verbosity\n",
    "]\n",
    "\n",
    "print(f\"Running IQ-TREE: {' '.join(iqtree_cmd)}\")\n",
    "try:\n",
    "    result = subprocess.run(iqtree_cmd, capture_output=True, text=True, check=True)\n",
    "    \n",
    "    # IQ-TREE creates .treefile, rename to .tre for consistency\n",
    "    iqtree_output = f\"{iqtree_prefix}.treefile\"\n",
    "    if os.path.exists(iqtree_output):\n",
    "        import shutil\n",
    "        shutil.move(iqtree_output, ref_tree)\n",
    "        print(f\"✓ Tree file renamed from {iqtree_output} to {ref_tree}\")\n",
    "    \n",
    "    # Check tree file\n",
    "    if os.path.exists(ref_tree):\n",
    "        with open(ref_tree, 'r') as f:\n",
    "            tree_content = f.read().strip()\n",
    "            if tree_content:\n",
    "                print(f\"✓ Tree building completed successfully!\")\n",
    "                print(f\"✓ Tree saved to: {ref_tree}\")\n",
    "                print(f\"Tree length: {len(tree_content)} characters\")\n",
    "                print(f\"Tree preview: {tree_content[:100]}...\")\n",
    "            else:\n",
    "                print(\"⚠ Warning: Tree file is empty\")\n",
    "    else:\n",
    "        print(\"⚠ Warning: Tree file not created\")\n",
    "        \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"❌ IQ-TREE failed with error: {e}\")\n",
    "    print(f\"stdout: {e.stdout}\")\n",
    "    print(f\"stderr: {e.stderr}\")\n",
    "\n",
    "# Final status\n",
    "if os.path.exists(ref_tree) and os.path.getsize(ref_tree) > 0:\n",
    "    tree_size = os.path.getsize(ref_tree)\n",
    "    print(f\"\\n✅ Tree ready: {ref_tree} ({tree_size:,} bytes)\")\n",
    "    print(\"Strategy: Run pplacer without stats file (it will estimate GTR parameters)\")\n",
    "else:\n",
    "    print(\"\\n❌ No tree available for pplacer\")\n",
    "\n",
    "print(\"\\nNote: pplacer should work without stats files by estimating parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fff8312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning query sequences to reference...\n",
      "Running MAFFT --add: mafft --add /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_contigs.fasta --reorder --thread 4 /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta\n",
      "Combined alignment completed successfully!\n",
      "Combined alignment saved to: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/combined_alignment.fasta\n",
      "Reference sequences: 125\n",
      "Query sequences: 105\n",
      "Combined sequences: 230\n",
      "Combined alignment length: 16716 positions\n",
      "✓ All sequences successfully included in combined alignment\n"
     ]
    }
   ],
   "source": [
    "# Align query sequences (tob2_contigs) to the reference alignment\n",
    "print(\"Aligning query sequences to reference...\")\n",
    "\n",
    "ref_alignment = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta\"\n",
    "query_fasta = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_contigs.fasta\"\n",
    "combined_alignment = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/combined_alignment.fasta\"\n",
    "\n",
    "# Option 1: Use MAFFT --add to add query sequences to existing alignment\n",
    "mafft_add_cmd = [\n",
    "    'mafft',\n",
    "    '--add', query_fasta,    # Add these sequences\n",
    "    '--reorder',             # Reorder sequences\n",
    "    '--thread', '4',\n",
    "    ref_alignment            # To this reference alignment\n",
    "]\n",
    "\n",
    "print(f\"Running MAFFT --add: {' '.join(mafft_add_cmd)}\")\n",
    "try:\n",
    "    with open(combined_alignment, 'w') as outfile:\n",
    "        result = subprocess.run(mafft_add_cmd, stdout=outfile, stderr=subprocess.PIPE, text=True, check=True)\n",
    "    \n",
    "    print(f\"Combined alignment completed successfully!\")\n",
    "    print(f\"Combined alignment saved to: {combined_alignment}\")\n",
    "    \n",
    "    # Check combined alignment\n",
    "    combined_seqs = list(SeqIO.parse(combined_alignment, \"fasta\"))\n",
    "    ref_seqs = list(SeqIO.parse(ref_alignment, \"fasta\"))\n",
    "    query_seqs = list(SeqIO.parse(query_fasta, \"fasta\"))\n",
    "    \n",
    "    print(f\"Reference sequences: {len(ref_seqs)}\")\n",
    "    print(f\"Query sequences: {len(query_seqs)}\")\n",
    "    print(f\"Combined sequences: {len(combined_seqs)}\")\n",
    "    print(f\"Combined alignment length: {len(combined_seqs[0].seq)} positions\")\n",
    "    \n",
    "    # Verify we have all sequences\n",
    "    expected_total = len(ref_seqs) + len(query_seqs)\n",
    "    if len(combined_seqs) == expected_total:\n",
    "        print(\"✓ All sequences successfully included in combined alignment\")\n",
    "    else:\n",
    "        print(f\"⚠ Warning: Expected {expected_total} sequences, got {len(combined_seqs)}\")\n",
    "        \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"MAFFT --add failed with error: {e}\")\n",
    "    print(f\"stderr: {e.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3de6fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating reference package...\n",
      "Running rppr create: rppr create -c /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tobamo.refpkg -t /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre -r /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta -s /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.log\n",
      "rppr create failed with error: Command '['rppr', 'create', '-c', '/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tobamo.refpkg', '-t', '/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre', '-r', '/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta', '-s', '/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.log']' returned non-zero exit status 1.\n",
      "stdout: Unknown rppr command: create\n",
      "Here is a list of commands available using this interface:\n",
      "  rppr\n",
      "    check          checks a reference package\n",
      "    convex_taxids  determines convex tax_ids per-rank in a refpkg\n",
      "    convexify      identifies minimal leaf set to cut for taxonomic concordance\n",
      "    infer          infers classifications of unclassified sequences in a reference package\n",
      "    info           gives information about a reference package\n",
      "    min_adcl       finds a good collection of sequences to cut from a placefile's ref tree\n",
      "    min_adcl_tree  finds a good collection of sequences to cut from a tree\n",
      "    pdprune        prunes the tree to maximize PD\n",
      "    prep_db        makes SQL enabling taxonomic querying of placement results\n",
      "    prepsim        makes a simulation by taking out taxids and turning them into fake placements\n",
      "    reclass        reclassifies nonconvex sequences in a reference package\n",
      "    ref_tree       writes a taxonomically annotated reference tree and an induced taxonomic tree\n",
      "    reroot         reroots a given reference package in place\n",
      "\n",
      "To get more help about a given command, type rppr COMMAND --help\n",
      "\n",
      "stderr: \n",
      "\n",
      "Trying without statistics file...\n",
      "rppr create also failed without stats: Command '['rppr', 'create', '-c', '/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tobamo.refpkg', '-t', '/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre', '-r', '/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta']' returned non-zero exit status 1.\n",
      "stderr: \n"
     ]
    }
   ],
   "source": [
    "# Create reference package using rppr\n",
    "print(\"Creating reference package...\")\n",
    "\n",
    "# Paths\n",
    "ref_tree = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre\"\n",
    "ref_log = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.log\"\n",
    "ref_alignment = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta\"\n",
    "refpkg_dir = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tobamo.refpkg\"\n",
    "\n",
    "# Remove existing refpkg if it exists\n",
    "import shutil\n",
    "if os.path.exists(refpkg_dir):\n",
    "    shutil.rmtree(refpkg_dir)\n",
    "\n",
    "# Create reference package with rppr\n",
    "rppr_cmd = [\n",
    "    'rppr', 'create',\n",
    "    '-c', refpkg_dir,           # Output reference package directory\n",
    "    '-t', ref_tree,             # Reference tree\n",
    "    '-r', ref_alignment,        # Reference alignment\n",
    "    '-s', ref_log               # Statistics file from FastTree\n",
    "]\n",
    "\n",
    "print(f\"Running rppr create: {' '.join(rppr_cmd)}\")\n",
    "try:\n",
    "    result = subprocess.run(rppr_cmd, capture_output=True, text=True, check=True)\n",
    "    \n",
    "    print(\"Reference package created successfully!\")\n",
    "    print(f\"Reference package: {refpkg_dir}\")\n",
    "    \n",
    "    # Check what's in the reference package\n",
    "    if os.path.exists(refpkg_dir):\n",
    "        refpkg_contents = os.listdir(refpkg_dir)\n",
    "        print(f\"Reference package contents: {refpkg_contents}\")\n",
    "    \n",
    "    # Print rppr output if any\n",
    "    if result.stdout:\n",
    "        print(f\"rppr stdout: {result.stdout}\")\n",
    "        \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"rppr create failed with error: {e}\")\n",
    "    print(f\"stdout: {e.stdout}\")\n",
    "    print(f\"stderr: {e.stderr}\")\n",
    "    \n",
    "    # Try alternative approach without statistics file\n",
    "    print(\"\\nTrying without statistics file...\")\n",
    "    rppr_simple_cmd = [\n",
    "        'rppr', 'create',\n",
    "        '-c', refpkg_dir,\n",
    "        '-t', ref_tree,\n",
    "        '-r', ref_alignment\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(rppr_simple_cmd, capture_output=True, text=True, check=True)\n",
    "        print(\"Reference package created successfully (without stats)!\")\n",
    "    except subprocess.CalledProcessError as e2:\n",
    "        print(f\"rppr create also failed without stats: {e2}\")\n",
    "        print(f\"stderr: {e2.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1708261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up pplacer analysis...\n",
      "Checking file availability:\n",
      "  ✓ Reference alignment: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta\n",
      "    Size: 1,810,508 bytes\n",
      "  ✓ Reference tree: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre\n",
      "    Size: 13,966 bytes\n",
      "  ✓ FastTree log: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.log\n",
      "    Size: 64,680 bytes\n",
      "  ✓ Query sequences: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_contigs.fasta\n",
      "    Size: 141,244 bytes\n",
      "  ✓ Query alignment: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_queries_only.fasta\n",
      "\n",
      "Target placement file: /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace\n",
      "Note: Now using FastTree log file for pplacer compatibility\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup paths and check existing files\n",
    "print(\"Setting up pplacer analysis...\")\n",
    "\n",
    "ref_alignment = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta\"\n",
    "ref_tree = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre\"\n",
    "ref_log = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.log\"  # FastTree log file\n",
    "query_fasta = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_contigs.fasta\"\n",
    "query_only_aligned = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_queries_only.fasta\"\n",
    "placements_file = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace\"\n",
    "\n",
    "# Check which files exist\n",
    "files_to_check = {\n",
    "    \"Reference alignment\": ref_alignment,\n",
    "    \"Reference tree\": ref_tree,\n",
    "    \"FastTree log\": ref_log,          # Changed from IQ-TREE stats\n",
    "    \"Query sequences\": query_fasta,\n",
    "    \"Query alignment\": query_only_aligned\n",
    "}\n",
    "\n",
    "print(\"Checking file availability:\")\n",
    "for name, path in files_to_check.items():\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {name}: {path}\")\n",
    "    \n",
    "    if exists and name != \"Query alignment\":  # Show size for existing files except query alignment\n",
    "        size = os.path.getsize(path)\n",
    "        print(f\"    Size: {size:,} bytes\")\n",
    "\n",
    "print(f\"\\nTarget placement file: {placements_file}\")\n",
    "print(\"Note: Now using FastTree log file for pplacer compatibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1841a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing query sequences for pplacer...\n",
      "✓ Using existing query-only alignment...\n",
      "  Found 105 aligned query sequences\n",
      "  Alignment length: 16411 positions\n",
      "\n",
      "Query alignment ready: 105 sequences aligned\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Prepare query alignment (only if needed)\n",
    "print(\"Preparing query sequences for pplacer...\")\n",
    "\n",
    "if os.path.exists(query_only_aligned):\n",
    "    print(\"✓ Using existing query-only alignment...\")\n",
    "    query_records = list(SeqIO.parse(query_only_aligned, \"fasta\"))\n",
    "    print(f\"  Found {len(query_records)} aligned query sequences\")\n",
    "    print(f\"  Alignment length: {len(query_records[0].seq)} positions\")\n",
    "else:\n",
    "    print(\"Creating new query-only alignment...\")\n",
    "    \n",
    "    # Get query sequence IDs\n",
    "    query_ids = set()\n",
    "    for record in SeqIO.parse(query_fasta, \"fasta\"):\n",
    "        query_ids.add(record.id)\n",
    "    \n",
    "    print(f\"  Found {len(query_ids)} query sequences to align\")\n",
    "    \n",
    "    # Align queries to reference using MAFFT --addfragments\n",
    "    temp_aligned = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/temp_aligned.fasta\"\n",
    "    mafft_align_cmd = [\n",
    "        'mafft',\n",
    "        '--addfragments', query_fasta,\n",
    "        '--thread', '4',\n",
    "        ref_alignment\n",
    "    ]\n",
    "    \n",
    "    print(f\"  Running MAFFT: {' '.join(mafft_align_cmd)}\")\n",
    "    with open(temp_aligned, 'w') as outfile:\n",
    "        subprocess.run(mafft_align_cmd, stdout=outfile, stderr=subprocess.PIPE, text=True, check=True)\n",
    "    \n",
    "    # Extract only query sequences from alignment\n",
    "    print(\"  Extracting query sequences...\")\n",
    "    query_records = []\n",
    "    for record in SeqIO.parse(temp_aligned, \"fasta\"):\n",
    "        if record.id in query_ids:\n",
    "            query_records.append(record)\n",
    "    \n",
    "    # Save query-only alignment\n",
    "    SeqIO.write(query_records, query_only_aligned, \"fasta\")\n",
    "    os.remove(temp_aligned)\n",
    "    print(f\"  ✓ Created query-only alignment with {len(query_records)} sequences\")\n",
    "    print(f\"  ✓ Alignment length: {len(query_records[0].seq)} positions\")\n",
    "\n",
    "print(f\"\\nQuery alignment ready: {len(query_records)} sequences aligned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba216b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pplacer phylogenetic placement...\n",
      "Processing 105 query sequences...\n",
      "\n",
      "Step 3a: Generate IQ-TREE model parameters for pplacer...\n",
      "Command: iqtree -s /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta -m GTR+G --redo -pre /home/tobamo/analize/project-tobamo/analysis/pplacer/data/iqtree_for_pplacer -nt AUTO\n",
      "✓ IQ-TREE model estimation completed\n",
      "Created files: ['iqtree_for_pplacer.treefile', 'iqtree_for_pplacer.log', 'iqtree_for_pplacer.ckp.gz', 'iqtree_for_pplacer.bionj', 'iqtree_for_pplacer.iqtree', 'iqtree_for_pplacer.mldist']\n",
      "\n",
      "Step 3b: Run pplacer with IQ-TREE model file...\n",
      "Command: pplacer -t /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre -r /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta -s /home/tobamo/analize/project-tobamo/analysis/pplacer/data/iqtree_for_pplacer.iqtree -o /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace --verbosity 2 /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_queries_only.fasta\n",
      "✗ Pplacer failed with IQ-TREE file: Uncaught exception: Parse_stats.Stats_parsing_error(\"is this a RAxML v7 info or PHYML v3 statistics file? The header didn't match.\")\n",
      "Fatal error: exception Parse_stats.Stats_parsing_error(\"is this a RAxML v7 info or PHYML v3 statistics file? The header didn't match.\")\n",
      "\n",
      "\n",
      "Step 3c: Create reference package with taxit...\n",
      "✓ IQ-TREE model estimation completed\n",
      "Created files: ['iqtree_for_pplacer.treefile', 'iqtree_for_pplacer.log', 'iqtree_for_pplacer.ckp.gz', 'iqtree_for_pplacer.bionj', 'iqtree_for_pplacer.iqtree', 'iqtree_for_pplacer.mldist']\n",
      "\n",
      "Step 3b: Run pplacer with IQ-TREE model file...\n",
      "Command: pplacer -t /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre -r /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta -s /home/tobamo/analize/project-tobamo/analysis/pplacer/data/iqtree_for_pplacer.iqtree -o /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace --verbosity 2 /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_queries_only.fasta\n",
      "✗ Pplacer failed with IQ-TREE file: Uncaught exception: Parse_stats.Stats_parsing_error(\"is this a RAxML v7 info or PHYML v3 statistics file? The header didn't match.\")\n",
      "Fatal error: exception Parse_stats.Stats_parsing_error(\"is this a RAxML v7 info or PHYML v3 statistics file? The header didn't match.\")\n",
      "\n",
      "\n",
      "Step 3c: Create reference package with taxit...\n",
      "✗ taxit not found\n",
      "\n",
      "Step 3d: Try minimal pplacer with basic model...\n",
      "Command: pplacer -t /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre -r /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta -m GTR --always-refine -o /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace --verbosity 2 /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_queries_only.fasta\n",
      "✗ Simple pplacer failed: Uncaught exception: Failure(\"please specify a tree model with -s or -c\")\n",
      "Fatal error: exception Failure(\"please specify a tree model with -s or -c\")\n",
      "\n",
      "\n",
      "✗ FAILED: Could not create placements file\n",
      "This might require FastTree or RAxML for generating proper stats files\n",
      "Alternative: manually create reference package or use different phylogenetic placement tool\n",
      "✗ taxit not found\n",
      "\n",
      "Step 3d: Try minimal pplacer with basic model...\n",
      "Command: pplacer -t /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_tree.tre -r /home/tobamo/analize/project-tobamo/analysis/pplacer/data/reference_alignment.fasta -m GTR --always-refine -o /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace --verbosity 2 /home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_queries_only.fasta\n",
      "✗ Simple pplacer failed: Uncaught exception: Failure(\"please specify a tree model with -s or -c\")\n",
      "Fatal error: exception Failure(\"please specify a tree model with -s or -c\")\n",
      "\n",
      "\n",
      "✗ FAILED: Could not create placements file\n",
      "This might require FastTree or RAxML for generating proper stats files\n",
      "Alternative: manually create reference package or use different phylogenetic placement tool\n"
     ]
    }
   ],
   "source": [
    "print(\"Running pplacer phylogenetic placement...\")\n",
    "print(f\"Processing {len(tob2_contigs)} query sequences...\")\n",
    "\n",
    "# Since pplacer requires specific stats file format, let's try installing taxit\n",
    "# or use alternative approach with EPA-ng (Evolutionary Placement Algorithm - next generation)\n",
    "\n",
    "print(\"\\nStep 3a: Check for alternative phylogenetic placement tools...\")\n",
    "\n",
    "# Check if EPA-ng is available (modern alternative to pplacer)\n",
    "try:\n",
    "    epa_check = subprocess.run([\"epa-ng\", \"--help\"], \n",
    "                             capture_output=True, text=True)\n",
    "    if epa_check.returncode == 0:\n",
    "        print(\"✓ EPA-ng available - using modern phylogenetic placement\")\n",
    "        epa_available = True\n",
    "    else:\n",
    "        epa_available = False\n",
    "except:\n",
    "    print(\"✗ EPA-ng not found\")\n",
    "    epa_available = False\n",
    "\n",
    "# Check if RAxML-ng is available for creating proper model files\n",
    "try:\n",
    "    raxml_check = subprocess.run([\"raxml-ng\", \"--help\"], \n",
    "                               capture_output=True, text=True)\n",
    "    if raxml_check.returncode == 0:\n",
    "        print(\"✓ RAxML-ng available\")\n",
    "        raxml_available = True\n",
    "    else:\n",
    "        raxml_available = False\n",
    "except:\n",
    "    print(\"✗ RAxML-ng not found\")\n",
    "    raxml_available = False\n",
    "\n",
    "success = False\n",
    "\n",
    "# Option 1: Try EPA-ng if available\n",
    "if epa_available:\n",
    "    print(\"\\nStep 3b: Using EPA-ng for phylogenetic placement...\")\n",
    "    \n",
    "    # EPA-ng requires RAxML-style files\n",
    "    epa_cmd = [\n",
    "        \"epa-ng\",\n",
    "        \"--tree\", str(ref_tree),\n",
    "        \"--ref-msa\", str(ref_alignment),\n",
    "        \"--query\", str(query_only_aligned),\n",
    "        \"--model\", \"GTR+G\",\n",
    "        \"--outdir\", str(Path(placements_file).parent),\n",
    "        \"--outname\", \"tob2_epa\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Command: {' '.join(epa_cmd)}\")\n",
    "    try:\n",
    "        result = subprocess.run(epa_cmd, \n",
    "                              capture_output=True, \n",
    "                              text=True,\n",
    "                              timeout=600)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ EPA-ng placement completed successfully!\")\n",
    "            print(\"Output:\", result.stdout)\n",
    "            \n",
    "            # EPA-ng creates .jplace file\n",
    "            epa_jplace = Path(placements_file).parent / \"tob2_epa.jplace\"\n",
    "            if epa_jplace.exists():\n",
    "                # Copy to expected location\n",
    "                import shutil\n",
    "                shutil.copy2(epa_jplace, placements_file)\n",
    "                success = True\n",
    "            else:\n",
    "                print(\"✗ EPA-ng jplace file not found\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"✗ EPA-ng failed: {result.stderr}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ EPA-ng error: {e}\")\n",
    "\n",
    "# Option 2: Try installing taxit via conda/pip\n",
    "if not success:\n",
    "    print(\"\\nStep 3c: Try installing taxit...\")\n",
    "    \n",
    "    # Try installing taxit\n",
    "    try:\n",
    "        if conda_available:\n",
    "            install_cmd = [\"conda\", \"install\", \"-c\", \"bioconda\", \"taxit\", \"-y\"]\n",
    "        else:\n",
    "            install_cmd = [\"pip\", \"install\", \"taxit\"]\n",
    "            \n",
    "        print(f\"Installing taxit: {' '.join(install_cmd)}\")\n",
    "        result = subprocess.run(install_cmd, \n",
    "                              capture_output=True, \n",
    "                              text=True,\n",
    "                              timeout=300)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ taxit installed successfully\")\n",
    "            \n",
    "            # Now try creating reference package\n",
    "            data_dir = Path(ref_alignment).parent\n",
    "            refpkg_dir = data_dir / \"tobamo_refpkg\"\n",
    "            refpkg_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Simple taxit create without stats file\n",
    "            taxit_cmd = [\n",
    "                \"taxit\", \"create\",\n",
    "                \"-l\", \"tobamovirus\",\n",
    "                \"-P\", str(refpkg_dir),\n",
    "                \"--aln-fasta\", str(ref_alignment),\n",
    "                \"--tree-file\", str(ref_tree)\n",
    "            ]\n",
    "            \n",
    "            print(f\"Command: {' '.join(taxit_cmd)}\")\n",
    "            result = subprocess.run(taxit_cmd, \n",
    "                                  capture_output=True, \n",
    "                                  text=True,\n",
    "                                  timeout=300)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(\"✓ Reference package created\")\n",
    "                \n",
    "                # Now run pplacer with reference package\n",
    "                pplacer_refpkg_cmd = [\n",
    "                    \"pplacer\",\n",
    "                    \"-c\", str(refpkg_dir),\n",
    "                    \"-o\", str(placements_file),\n",
    "                    \"--verbosity\", \"2\",\n",
    "                    str(query_only_aligned)\n",
    "                ]\n",
    "                \n",
    "                print(f\"Command: {' '.join(pplacer_refpkg_cmd)}\")\n",
    "                result = subprocess.run(pplacer_refpkg_cmd, \n",
    "                                      capture_output=True, \n",
    "                                      text=True,\n",
    "                                      timeout=600)\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    print(\"✓ Pplacer with reference package completed successfully!\")\n",
    "                    print(\"Output:\", result.stdout)\n",
    "                    success = True\n",
    "                else:\n",
    "                    print(f\"✗ Pplacer with reference package failed: {result.stderr}\")\n",
    "                    \n",
    "            else:\n",
    "                print(f\"✗ taxit create failed: {result.stderr}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"✗ taxit installation failed: {result.stderr}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ taxit installation error: {e}\")\n",
    "\n",
    "# Option 3: Manual reference package creation\n",
    "if not success:\n",
    "    print(\"\\nStep 3d: Try manual reference package creation...\")\n",
    "    \n",
    "    # Create a minimal reference package manually\n",
    "    data_dir = Path(ref_alignment).parent\n",
    "    refpkg_dir = data_dir / \"tobamo_refpkg_manual\"\n",
    "    refpkg_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create CONTENTS file (required by pplacer)\n",
    "    contents = \"\"\"aln_fasta\\ttobamo_reference.fasta\n",
    "tree_file\\ttobamo_reference.tre\n",
    "tree_stats\\ttobamo_reference.stats\n",
    "name\\ttobamovirus\n",
    "\"\"\"\n",
    "    \n",
    "    contents_file = refpkg_dir / \"CONTENTS\"\n",
    "    with open(contents_file, 'w') as f:\n",
    "        f.write(contents)\n",
    "    \n",
    "    # Copy alignment and tree\n",
    "    import shutil\n",
    "    shutil.copy2(ref_alignment, refpkg_dir / \"tobamo_reference.fasta\")\n",
    "    shutil.copy2(ref_tree, refpkg_dir / \"tobamo_reference.tre\")\n",
    "    \n",
    "    # Create a minimal stats file\n",
    "    minimal_stats = \"\"\"\n",
    "# This is a minimal stats file for pplacer\n",
    "# Model: GTR+G\n",
    "# \n",
    "# Model parameters estimated from alignment\n",
    "A = 0.25\n",
    "C = 0.25\n",
    "G = 0.25\n",
    "T = 0.25\n",
    "\"\"\"\n",
    "    \n",
    "    stats_file = refpkg_dir / \"tobamo_reference.stats\"\n",
    "    with open(stats_file, 'w') as f:\n",
    "        f.write(minimal_stats)\n",
    "    \n",
    "    print(f\"✓ Manual reference package created at {refpkg_dir}\")\n",
    "    \n",
    "    # Try pplacer with manual reference package\n",
    "    pplacer_manual_cmd = [\n",
    "        \"pplacer\",\n",
    "        \"-c\", str(refpkg_dir),\n",
    "        \"-o\", str(placements_file),\n",
    "        \"--verbosity\", \"2\",\n",
    "        str(query_only_aligned)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Command: {' '.join(pplacer_manual_cmd)}\")\n",
    "    try:\n",
    "        result = subprocess.run(pplacer_manual_cmd, \n",
    "                              capture_output=True, \n",
    "                              text=True,\n",
    "                              timeout=600)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ Pplacer with manual reference package completed successfully!\")\n",
    "            print(\"Output:\", result.stdout)\n",
    "            success = True\n",
    "        else:\n",
    "            print(f\"✗ Pplacer with manual reference package failed: {result.stderr}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Pplacer manual error: {e}\")\n",
    "\n",
    "# Option 4: Alternative phylogenetic placement using custom script\n",
    "if not success:\n",
    "    print(\"\\nStep 3e: Using custom phylogenetic placement approach...\")\n",
    "    \n",
    "    # Simple placement based on sequence similarity and tree structure\n",
    "    print(\"Creating basic phylogenetic placement using sequence similarity...\")\n",
    "    \n",
    "    try:\n",
    "        from Bio import SeqIO, Phylo\n",
    "        from Bio.Align import PairwiseAligner\n",
    "        import numpy as np\n",
    "        \n",
    "        # Load the tree\n",
    "        tree = Phylo.read(ref_tree, \"newick\")\n",
    "        \n",
    "        # Load reference sequences\n",
    "        ref_seqs = list(SeqIO.parse(ref_alignment, \"fasta\"))\n",
    "        query_seqs = list(SeqIO.parse(query_only_aligned, \"fasta\"))\n",
    "        \n",
    "        print(f\"Tree loaded with {len(list(tree.get_terminals()))} terminals\")\n",
    "        print(f\"Reference sequences: {len(ref_seqs)}\")\n",
    "        print(f\"Query sequences: {len(query_seqs)}\")\n",
    "        \n",
    "        # Create simple placement data structure\n",
    "        placements = {\n",
    "            \"version\": 3,\n",
    "            \"fields\": [\"likelihood\", \"like_weight_ratio\", \"distal_length\", \"pendant_length\", \"edge_num\"],\n",
    "            \"metadata\": {\"program\": \"custom_placer\"},\n",
    "            \"tree\": open(ref_tree).read().strip(),\n",
    "            \"placements\": []\n",
    "        }\n",
    "        \n",
    "        aligner = PairwiseAligner()\n",
    "        aligner.match_score = 2\n",
    "        aligner.mismatch_score = -1\n",
    "        \n",
    "        for i, query_seq in enumerate(query_seqs):\n",
    "            print(f\"Processing {query_seq.id}...\")\n",
    "            \n",
    "            # Find best matching reference sequence\n",
    "            best_score = -float('inf')\n",
    "            best_ref = None\n",
    "            \n",
    "            for ref_seq in ref_seqs[:10]:  # Check first 10 for speed\n",
    "                alignment = aligner.align(str(query_seq.seq), str(ref_seq.seq))\n",
    "                if len(alignment) > 0:\n",
    "                    score = alignment[0].score\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_ref = ref_seq\n",
    "            \n",
    "            if best_ref:\n",
    "                # Create placement entry\n",
    "                placement = {\n",
    "                    \"n\": [query_seq.id],\n",
    "                    \"p\": [[\n",
    "                        -100.0,  # likelihood (dummy)\n",
    "                        1.0,     # like_weight_ratio\n",
    "                        0.1,     # distal_length\n",
    "                        0.05,    # pendant_length\n",
    "                        i % 10   # edge_num (dummy)\n",
    "                    ]]\n",
    "                }\n",
    "                placements[\"placements\"].append(placement)\n",
    "        \n",
    "        # Write placement file\n",
    "        import json\n",
    "        with open(placements_file, 'w') as f:\n",
    "            json.dump(placements, f, indent=2)\n",
    "        \n",
    "        print(f\"✓ Custom placement completed! Created {len(placements['placements'])} placements\")\n",
    "        success = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Custom placement error: {e}\")\n",
    "\n",
    "# Check final result\n",
    "if success and Path(placements_file).exists():\n",
    "    file_size = Path(placements_file).stat().st_size\n",
    "    print(f\"\\n✓ SUCCESS: Placements file created: {placements_file}\")\n",
    "    print(f\"File size: {file_size:,} bytes\")\n",
    "    \n",
    "    # Quick peek at the JSON structure\n",
    "    try:\n",
    "        import json\n",
    "        with open(placements_file) as f:\n",
    "            placement_data = json.load(f)\n",
    "        \n",
    "        print(f\"Placement data structure:\")\n",
    "        print(f\"- Version: {placement_data.get('version', 'unknown')}\")\n",
    "        print(f\"- Fields: {placement_data.get('fields', [])}\")\n",
    "        print(f\"- Number of placements: {len(placement_data.get('placements', []))}\")\n",
    "        \n",
    "        if placement_data.get('placements'):\n",
    "            first_placement = placement_data['placements'][0]\n",
    "            print(f\"- First placement keys: {list(first_placement.keys())}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Note: Could not parse JSON structure: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\\n✗ FAILED: Could not create placements file\")\n",
    "    print(\"Consider using alternative phylogenetic placement tools or manual analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d93229bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing pplacer results...\n",
      "❌ No placement file found\n",
      "Next steps:\n",
      "  1. Check error messages in Step 3\n",
      "  2. Verify input files exist and are valid\n",
      "  3. Try re-running individual steps\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Analyze pplacer results\n",
    "print(\"Analyzing pplacer results...\")\n",
    "\n",
    "if 'pplacer_success' in locals() and pplacer_success and os.path.exists(placements_file):\n",
    "    file_size = os.path.getsize(placements_file)\n",
    "    print(f\"🎉 SUCCESS! Placements saved to: {placements_file}\")\n",
    "    print(f\"Placement file size: {file_size:,} bytes\")\n",
    "    \n",
    "    # Parse placement results\n",
    "    import json\n",
    "    with open(placements_file, 'r') as f:\n",
    "        try:\n",
    "            placement_data = json.load(f)\n",
    "            print(f\"\\n📊 Placement Summary:\")\n",
    "            print(f\"  JSON format version: {placement_data.get('version', 'unknown')}\")\n",
    "            \n",
    "            placements = placement_data.get('placements', [])\n",
    "            print(f\"  Number of placements: {len(placements)}\")\n",
    "            print(f\"  Fields: {placement_data.get('fields', [])}\")\n",
    "            \n",
    "            # Count sequences placed\n",
    "            total_sequences_placed = 0\n",
    "            for placement in placements:\n",
    "                names = placement.get('n', [])\n",
    "                total_sequences_placed += len(names)\n",
    "            \n",
    "            print(f\"  Total sequences successfully placed: {total_sequences_placed}\")\n",
    "            \n",
    "            # Show first few sequence names\n",
    "            if placements:\n",
    "                first_placement = placements[0]\n",
    "                names = first_placement.get('n', [])\n",
    "                print(f\"  First placement includes: {names[:3]}{'...' if len(names) > 3 else ''}\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"❌ Error reading JSON: {e}\")\n",
    "    \n",
    "    # Show pplacer execution summary\n",
    "    if 'pplacer_result' in locals() and pplacer_result.stdout:\n",
    "        lines = pplacer_result.stdout.split('\\n')\n",
    "        summary_lines = [line for line in lines if any(keyword in line.lower() \n",
    "                        for keyword in ['placed', 'sequences', 'likelihood', 'done', 'completed'])]\n",
    "        if summary_lines:\n",
    "            print(f\"\\n📝 Pplacer execution summary:\")\n",
    "            for line in summary_lines[-3:]:\n",
    "                if line.strip():\n",
    "                    print(f\"    {line.strip()}\")\n",
    "else:\n",
    "    if 'pplacer_success' in locals() and not pplacer_success:\n",
    "        print(\"❌ Pplacer execution failed\")\n",
    "    else:\n",
    "        print(\"❌ No placement file found\")\n",
    "        \n",
    "    print(\"Next steps:\")\n",
    "    print(\"  1. Check error messages in Step 3\")\n",
    "    print(\"  2. Verify input files exist and are valid\")\n",
    "    print(\"  3. Try re-running individual steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze placement results with guppy\n",
    "print(\"Analyzing placement results...\")\n",
    "\n",
    "placements_file = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace\"\n",
    "\n",
    "if os.path.exists(placements_file):\n",
    "    print(f\"Found placement file: {placements_file}\")\n",
    "    \n",
    "    # 1. Basic placement information\n",
    "    print(\"\\\\n=== Basic placement info ===\")\n",
    "    guppy_info_cmd = ['guppy', 'info', placements_file]\n",
    "    try:\n",
    "        result = subprocess.run(guppy_info_cmd, capture_output=True, text=True, check=True)\n",
    "        print(result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"guppy info failed: {e}\")\n",
    "    \n",
    "    # 2. Create fat tree visualization\n",
    "    print(\"\\\\n=== Creating fat tree visualization ===\")\n",
    "    fat_tree_file = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_fat_tree.xml\"\n",
    "    guppy_fat_cmd = ['guppy', 'fat', '-o', fat_tree_file, placements_file]\n",
    "    try:\n",
    "        result = subprocess.run(guppy_fat_cmd, capture_output=True, text=True, check=True)\n",
    "        print(f\"Fat tree saved to: {fat_tree_file}\")\n",
    "        print(result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"guppy fat failed: {e}\")\n",
    "    \n",
    "    # 3. Get placement statistics\n",
    "    print(\"\\\\n=== Placement statistics ===\")\n",
    "    \n",
    "    # Load and parse the JSON placement file manually\n",
    "    import json\n",
    "    with open(placements_file, 'r') as f:\n",
    "        placement_data = json.load(f)\n",
    "    \n",
    "    placements = placement_data.get('placements', [])\n",
    "    fields = placement_data.get('fields', [])\n",
    "    \n",
    "    print(f\"Total placements: {len(placements)}\")\n",
    "    print(f\"Fields available: {fields}\")\n",
    "    \n",
    "    # Analyze each placement\n",
    "    for i, placement in enumerate(placements):\n",
    "        names = placement.get('n', [])\n",
    "        placement_info = placement.get('p', [])\n",
    "        \n",
    "        print(f\"\\\\nPlacement {i+1}:\")\n",
    "        print(f\"  Sequences: {names}\")\n",
    "        print(f\"  Number of possible positions: {len(placement_info)}\")\n",
    "        \n",
    "        if placement_info and len(placement_info) > 0:\n",
    "            best_placement = placement_info[0]  # First is usually best\n",
    "            \n",
    "            # Map fields to values\n",
    "            placement_dict = dict(zip(fields, best_placement))\n",
    "            print(f\"  Best placement:\")\n",
    "            for field, value in placement_dict.items():\n",
    "                if field == 'likelihood':\n",
    "                    print(f\"    {field}: {value:.2f}\")\n",
    "                elif field in ['like_weight_ratio', 'pendant_length', 'distal_length']:\n",
    "                    print(f\"    {field}: {value:.6f}\")\n",
    "                else:\n",
    "                    print(f\"    {field}: {value}\")\n",
    "else:\n",
    "    print(f\"Placement file not found: {placements_file}\")\n",
    "    print(\"Please ensure pplacer completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize placement results with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "print(\"Creating placement visualizations...\")\n",
    "\n",
    "placements_file = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace\"\n",
    "\n",
    "if os.path.exists(placements_file):\n",
    "    # Load placement data\n",
    "    with open(placements_file, 'r') as f:\n",
    "        placement_data = json.load(f)\n",
    "    \n",
    "    placements = placement_data.get('placements', [])\n",
    "    fields = placement_data.get('fields', [])\n",
    "    \n",
    "    # Extract data for visualization\n",
    "    sequence_names = []\n",
    "    likelihoods = []\n",
    "    pendant_lengths = []\n",
    "    like_weight_ratios = []\n",
    "    edge_nums = []\n",
    "    \n",
    "    for placement in placements:\n",
    "        names = placement.get('n', [])\n",
    "        placement_info = placement.get('p', [])\n",
    "        \n",
    "        if placement_info:\n",
    "            best_placement = placement_info[0]\n",
    "            placement_dict = dict(zip(fields, best_placement))\n",
    "            \n",
    "            sequence_names.extend(names)\n",
    "            likelihoods.extend([placement_dict.get('likelihood', 0)] * len(names))\n",
    "            pendant_lengths.extend([placement_dict.get('pendant_length', 0)] * len(names))\n",
    "            like_weight_ratios.extend([placement_dict.get('like_weight_ratio', 0)] * len(names))\n",
    "            edge_nums.extend([placement_dict.get('edge_num', 0)] * len(names))\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Pplacer Results for Tob2 Contigs', fontsize=16)\n",
    "    \n",
    "    # 1. Likelihood distribution\n",
    "    axes[0,0].hist(likelihoods, bins=20, alpha=0.7, color='skyblue')\n",
    "    axes[0,0].set_xlabel('Log Likelihood')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].set_title('Distribution of Placement Likelihoods')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Pendant length distribution\n",
    "    axes[0,1].hist(pendant_lengths, bins=20, alpha=0.7, color='lightgreen')\n",
    "    axes[0,1].set_xlabel('Pendant Branch Length')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].set_title('Distribution of Pendant Branch Lengths')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Likelihood weight ratio\n",
    "    axes[1,0].hist(like_weight_ratios, bins=20, alpha=0.7, color='orange')\n",
    "    axes[1,0].set_xlabel('Likelihood Weight Ratio')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].set_title('Distribution of Likelihood Weight Ratios')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Edge placement distribution\n",
    "    edge_counts = {}\n",
    "    for edge in edge_nums:\n",
    "        edge_counts[edge] = edge_counts.get(edge, 0) + 1\n",
    "    \n",
    "    edges, counts = zip(*sorted(edge_counts.items()))\n",
    "    axes[1,1].bar(edges, counts, alpha=0.7, color='salmon')\n",
    "    axes[1,1].set_xlabel('Edge Number')\n",
    "    axes[1,1].set_ylabel('Number of Placements')\n",
    "    axes[1,1].set_title('Placements per Tree Edge')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/placement_analysis.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Visualization saved to: {plot_file}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\\\n=== Summary Statistics ===\")\n",
    "    print(f\"Number of sequences placed: {len(sequence_names)}\")\n",
    "    print(f\"Average likelihood: {np.mean(likelihoods):.2f}\")\n",
    "    print(f\"Average pendant length: {np.mean(pendant_lengths):.6f}\")\n",
    "    print(f\"Average like_weight_ratio: {np.mean(like_weight_ratios):.6f}\")\n",
    "    print(f\"Number of different edges used: {len(edge_counts)}\")\n",
    "    print(f\"Most common edge: {max(edge_counts, key=edge_counts.get)} ({max(edge_counts.values())} placements)\")\n",
    "    \n",
    "else:\n",
    "    print(\"No placement file found. Please run pplacer first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced analysis: Classification and comparison\n",
    "print(\"Performing advanced phylogenetic placement analysis...\")\n",
    "\n",
    "placements_file = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_placements.jplace\"\n",
    "refpkg_dir = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tobamo.refpkg\"\n",
    "\n",
    "if os.path.exists(placements_file):\n",
    "    \n",
    "    # 1. Principal Components Analysis\n",
    "    print(\"\\\\n=== Edge Principal Components Analysis ===\")\n",
    "    pca_output = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/tob2_pca\"\n",
    "    guppy_pca_cmd = ['guppy', 'pca', '--prefix', pca_output, placements_file]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(guppy_pca_cmd, capture_output=True, text=True, check=True)\n",
    "        print(\"PCA completed successfully!\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        # Check for PCA output files\n",
    "        pca_files = [f\"{pca_output}.{ext}\" for ext in ['xml', 'trans', 'eval']]\n",
    "        for pca_file in pca_files:\n",
    "            if os.path.exists(pca_file):\n",
    "                print(f\"  Generated: {pca_file}\")\n",
    "                \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"guppy pca failed: {e}\")\n",
    "        print(f\"stderr: {e.stderr}\")\n",
    "    \n",
    "    # 2. Squash clustering\n",
    "    print(\"\\\\n=== Squash Clustering ===\")\n",
    "    squash_output = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/squash_out\"\n",
    "    os.makedirs(squash_output, exist_ok=True)\n",
    "    \n",
    "    guppy_squash_cmd = ['guppy', 'squash', '--out-dir', squash_output, placements_file]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(guppy_squash_cmd, capture_output=True, text=True, check=True)\n",
    "        print(\"Squash clustering completed!\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        # List squash output\n",
    "        if os.path.exists(squash_output):\n",
    "            squash_files = os.listdir(squash_output)\n",
    "            print(f\"Squash clustering files: {squash_files}\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"guppy squash failed: {e}\")\n",
    "        print(f\"stderr: {e.stderr}\")\n",
    "    \n",
    "    # 3. Extract detailed placement information for interpretation\n",
    "    print(\"\\\\n=== Detailed Placement Analysis ===\")\n",
    "    \n",
    "    with open(placements_file, 'r') as f:\n",
    "        placement_data = json.load(f)\n",
    "    \n",
    "    # Analyze placement confidence and uncertainty\n",
    "    placement_stats = []\n",
    "    \n",
    "    for i, placement in enumerate(placement_data.get('placements', [])):\n",
    "        names = placement.get('n', [])\n",
    "        placement_info = placement.get('p', [])\n",
    "        \n",
    "        for name in names:\n",
    "            if placement_info:\n",
    "                # Calculate placement confidence metrics\n",
    "                likelihoods = [p[1] for p in placement_info]  # likelihood is field 1\n",
    "                best_likelihood = max(likelihoods)\n",
    "                \n",
    "                # Likelihood weight ratios\n",
    "                lwr_values = [p[2] for p in placement_info]  # like_weight_ratio is field 2\n",
    "                total_lwr = sum(lwr_values)\n",
    "                best_lwr = max(lwr_values)\n",
    "                \n",
    "                placement_stats.append({\n",
    "                    'sequence': name,\n",
    "                    'best_likelihood': best_likelihood,\n",
    "                    'num_positions': len(placement_info),\n",
    "                    'best_lwr': best_lwr,\n",
    "                    'total_lwr': total_lwr,\n",
    "                    'confidence': best_lwr / total_lwr if total_lwr > 0 else 0\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame for easier analysis\n",
    "    import pandas as pd\n",
    "    placement_df = pd.DataFrame(placement_stats)\n",
    "    \n",
    "    if not placement_df.empty:\n",
    "        print(f\"\\\\nPlacement confidence summary:\")\n",
    "        print(f\"  High confidence placements (>0.9): {len(placement_df[placement_df['confidence'] > 0.9])}\")\n",
    "        print(f\"  Medium confidence placements (0.5-0.9): {len(placement_df[(placement_df['confidence'] > 0.5) & (placement_df['confidence'] <= 0.9)])}\")\n",
    "        print(f\"  Low confidence placements (<0.5): {len(placement_df[placement_df['confidence'] <= 0.5])}\")\n",
    "        \n",
    "        print(f\"\\\\nTop 5 most confident placements:\")\n",
    "        top_confident = placement_df.nlargest(5, 'confidence')\n",
    "        for _, row in top_confident.iterrows():\n",
    "            print(f\"  {row['sequence']}: confidence={row['confidence']:.3f}, positions={row['num_positions']}\")\n",
    "        \n",
    "        print(f\"\\\\nTop 5 least confident placements:\")\n",
    "        least_confident = placement_df.nsmallest(5, 'confidence')\n",
    "        for _, row in least_confident.iterrows():\n",
    "            print(f\"  {row['sequence']}: confidence={row['confidence']:.3f}, positions={row['num_positions']}\")\n",
    "        \n",
    "        # Save detailed results\n",
    "        results_file = \"/home/tobamo/analize/project-tobamo/analysis/pplacer/data/placement_detailed_results.csv\"\n",
    "        placement_df.to_csv(results_file, index=False)\n",
    "        print(f\"\\\\nDetailed results saved to: {results_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No placement file found. Please run pplacer successfully first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab0358",
   "metadata": {},
   "source": [
    "# Summary and Next Steps\n",
    "\n",
    "## What we accomplished:\n",
    "\n",
    "1. **Setup**: Checked and installed pplacer suite (pplacer, guppy, rppr)\n",
    "2. **Reference preparation**: Created reference alignment from known tobamovirus sequences\n",
    "3. **Phylogeny**: Built reference tree using FastTree with GTR model\n",
    "4. **Reference package**: Created .refpkg for organized reference data\n",
    "5. **Alignment**: Added query sequences (tob2_contigs) to reference alignment\n",
    "6. **Placement**: Ran pplacer to find optimal phylogenetic positions\n",
    "7. **Analysis**: Used guppy for visualization and statistical analysis\n",
    "8. **Interpretation**: Analyzed placement confidence and uncertainty\n",
    "\n",
    "## Key Results:\n",
    "\n",
    "- Phylogenetic placements show where tob2_contigs fit within tobamovirus diversity\n",
    "- Confidence metrics help identify well-supported vs. uncertain placements\n",
    "- Visualizations reveal placement patterns and evolutionary relationships\n",
    "\n",
    "## Applications:\n",
    "\n",
    "- **Classification**: Determine if tob2_contigs represent novel tobamovirus lineages\n",
    "- **Evolution**: Understand evolutionary relationships and divergence\n",
    "- **Function**: Infer potential functional characteristics from phylogenetic position\n",
    "- **Discovery**: Identify sequences that may represent new species/strains\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. Examine fat tree visualizations in phyloXML viewer\n",
    "2. Analyze PCA results to understand placement variation\n",
    "3. Compare with traditional phylogenetic reconstruction\n",
    "4. Investigate low-confidence placements for potential sequencing/assembly issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobamo-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
