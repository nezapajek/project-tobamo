{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4969e2bd",
   "metadata": {},
   "source": [
    "# Comparison of Different Taxonomic Classification Approaches\n",
    "\n",
    "This notebook compares the performance and results of different taxonomic classification methods:\n",
    "\n",
    "1. **Manual Curation** - Ground truth from expert manual annotation\n",
    "2. **DIAMOND** - Traditional BLAST-like sequence alignment tool\n",
    "3. **MEGAN6** - Metagenome analysis tool\n",
    "4. **Palmprint Results** - Novel palmprint-based classification (to be generated)\n",
    "5. **Model Predictions** - Machine learning model predictions\n",
    "\n",
    "## Objectives\n",
    "- Compare accuracy and precision across methods\n",
    "- Identify strengths and weaknesses of each approach\n",
    "- Analyze computational efficiency and scalability\n",
    "- Generate comprehensive performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8840eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append('../scripts')\n",
    "from utils import *\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5084e9",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Load results from all classification approaches for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d427525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/home/tobamo/analize/project-tobamo/analysis/data/domain_sci_input/Tobamo - tabela za tobamo kontige - kategorije_2025-09-23.xlsx', header=0, skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c843c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "results_dir = os.makedirs('results/comparison_study', exist_ok=True)\n",
    "\n",
    "ground_truth = pd.read_excel('/home/tobamo/analize/project-tobamo/analysis/data/domain_sci_input/ground_truth_final_added_categories.xlsx')\n",
    "diamond_megan_results = pd.read_csv('/home/tobamo/analize/project-tobamo/results/megan6_results_combined_add_nr_taxa.csv')\n",
    "model_predictions = pd.read_csv('/home/tobamo/analize/project-tobamo/analysis/model/results/snakemake/predictions/contig_predictions.csv')\n",
    "palmprint = SeqIO.to_dict(SeqIO.parse('/home/tobamo/analize/project-tobamo/analysis/palmprint/results/palmscan/palmscan_pp_find0.fa','fasta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9445da9",
   "metadata": {},
   "source": [
    "## Method 0: Manual Curation (Ground Truth)\n",
    "\n",
    "Expert manual annotations serving as ground truth for comparison.\n",
    "\n",
    "### Key Features:\n",
    "- High accuracy from expert knowledge\n",
    "- Time-intensive process\n",
    "- Serves as benchmark for other methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e688f",
   "metadata": {},
   "source": [
    "## Method 1: PALMPRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d013bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "palmprint_positive_contigs = ['_'.join(k.split('_')[:-1]) for k in palmprint.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "716b976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 actual tobamo out of 228 assigned tobamo, which is (17.5%) total assigned tobamo\n"
     ]
    }
   ],
   "source": [
    "df['palmprint'] = np.where(df['contig_id'].isin(palmprint_positive_contigs), 1, 0)\n",
    "tobamo_palmprints = df[(df['palmprint'] == 1) & (df['ground_truth_category'].isin(['tob1','tob2','tob3']))]\n",
    "\n",
    "print(f\"{len(tobamo_palmprints)} actual tobamo out of {df[df['ground_truth_category'].isin(['tob1','tob2','tob3'])].shape[0]} assigned tobamo, which is ({len(tobamo_palmprints) / df[df['ground_truth_category'].isin(['tob1','tob2','tob3'])].shape[0] * 100:.1f}%) total assigned tobamo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45dc494",
   "metadata": {},
   "source": [
    "## Method 2: DIAMOND Classification\n",
    "\n",
    "Traditional sequence alignment-based classification using DIAMOND.\n",
    "\n",
    "### Key Features:\n",
    "- Fast BLAST-like sequence aligner\n",
    "- Well-established and widely used\n",
    "- Provides alignment scores and e-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3337ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 actual tobamo out of 228 assigned tobamo, which is (81.6%) total assigned tobamo\n"
     ]
    }
   ],
   "source": [
    "nt_tobamo = df[(df['first_diamond_blastx_hit_name'].str.contains('tobamovirus', case=False, na=False)) & (df['ground_truth_category'].isin(['tob1','tob2','tob3']))]\n",
    "print(f\"{df[(df['first_diamond_blastx_hit_name'].str.contains('tobamovirus', case=False, na=False)) & (df['ground_truth_category'].isin(['tob1','tob2','tob3']))].shape[0]} actual tobamo out of {df[df['ground_truth_category'].isin(['tob1','tob2','tob3'])].shape[0]} assigned tobamo, which is ({df[(df['first_diamond_blastx_hit_name'].str.contains('tobamovirus', case=False, na=False)) & (df['ground_truth_category'].isin(['tob1','tob2','tob3']))].shape[0] / df[df['ground_truth_category'].isin(['tob1','tob2','tob3'])].shape[0] * 100:.1f}%) total assigned tobamo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814a587",
   "metadata": {},
   "source": [
    "## Method 3: MEGAN6 Classification\n",
    "\n",
    "Metagenome analysis using MEGAN6 for taxonomic assignment.\n",
    "\n",
    "### Key Features:\n",
    "- Specialized for metagenome analysis\n",
    "- Uses LCA (Lowest Common Ancestor) algorithm\n",
    "- Integrates multiple alignment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a684b01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202 actual tobamo out of 228 assigned tobamo, which is (88.6%) total assigned tobamo\n"
     ]
    }
   ],
   "source": [
    "# MEGAN6 results analysis\n",
    "# Extract MEGAN6 specific results from the combined file\n",
    "\n",
    "diamond_megan_results.drop_duplicates(subset='qseqid', keep='first')\n",
    "megan_tax_mapper = diamond_megan_results.set_index('qseqid')['megan_tax'].to_dict()\n",
    "df['megan_tax'] = df['contig_id'].map(megan_tax_mapper)\n",
    "\n",
    "megan_tobamo = df[(df['megan_tax'].str.contains('tobamovirus', case=False, na=False)) & (df['ground_truth_category'].isin(['tob1','tob2','tob3']))]\n",
    "print(f\"{megan_tobamo.shape[0]} actual tobamo out of {df['ground_truth_category'].isin(['tob1','tob2','tob3']).sum()} assigned tobamo, which is ({megan_tobamo.shape[0] / df['ground_truth_category'].isin(['tob1','tob2','tob3']).sum() * 100:.1f}%) total assigned tobamo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306a861",
   "metadata": {},
   "source": [
    "## Method 4: Machine Learning Model Predictions\n",
    "\n",
    "Analysis of ML model-based taxonomic predictions.\n",
    "\n",
    "### Key Features:\n",
    "- Trained on curated datasets\n",
    "- Can learn complex patterns in sequence data\n",
    "- Provides confidence scores for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f206ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 actual tobamo out of 228 assigned tobamo, which is (93.0%) total assigned tobamo\n"
     ]
    }
   ],
   "source": [
    "model_tobamo = df[(df['model_prediction'] == 1) & (df['ground_truth_category'].isin(['tob1','tob2','tob3']))]\n",
    "print(f\"{model_tobamo.shape[0]} actual tobamo out of {df['ground_truth_category'].isin(['tob1','tob2','tob3']).sum()} assigned tobamo, which is ({model_tobamo.shape[0] / df['ground_truth_category'].isin(['tob1','tob2','tob3']).sum() * 100:.1f}%) total assigned tobamo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7fa6a",
   "metadata": {},
   "source": [
    "## Comparative Analysis\n",
    "\n",
    "Direct comparison of all methods across multiple metrics.\n",
    "\n",
    "### Performance Metrics\n",
    "- **Accuracy**: Overall correct classifications\n",
    "- **Precision**: True positives / (True positives + False positives)\n",
    "- **Recall**: True positives / (True positives + False negatives)\n",
    "- **F1 Score**: Harmonic mean of precision and recall\n",
    "- **Computational Time**: Time required for classification\n",
    "- **Resource Usage**: Memory and CPU requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a295c0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== METHOD-SPECIFIC ANALYSIS ===\n",
      "\n",
      "Available columns in datasets:\n",
      "Ground Truth columns: ['contig_name', 'ground_truth', 'category_old', 'category']\n",
      "DIAMOND/MEGAN columns: ['SRR', 'qseqid', 'megan_tax', 'nr_tax', 'tpdb2_sseqid', 'nr_sseqid', 'nr_pident', 'nr_length', 'nr_mismatch', 'nr_gapopen', 'nr_qstart', 'nr_qend', 'nr_sstart', 'nr_send', 'nr_evalue', 'nr_bitscore', 'tpdb2_pident', 'tpdb2_length', 'tpdb2_mismatch', 'tpdb2_gapopen', 'tpdb2_qstart', 'tpdb2_qend', 'tpdb2_sstart', 'tpdb2_send', 'tpdb2_evalue', 'tpdb2_bitscore', 'sequence', 'nr_sseqid_key']\n",
      "Model predictions columns: ['contig_name', 'predicted_class', 'prob_1']\n",
      "\n",
      "1. ðŸ“‹ MANUAL CURATION (Ground Truth):\n",
      "   Total samples: 510\n",
      "   No family column found in ground truth data\n",
      "\n",
      "2. ðŸ’Ž DIAMOND/MEGAN Analysis:\n",
      "   Total samples processed: 161333\n",
      "   Tobamovirus-positive samples: 202\n",
      "\n",
      "3. ðŸ¤– MACHINE LEARNING MODEL:\n",
      "   Total predictions: 510\n",
      "   Tobamovirus predictions: 212\n",
      "   Confidence columns available: ['prob_1']\n",
      "\n",
      "4. ðŸ–¨ï¸ PALMPRINT Analysis:\n",
      "   Total positive hits: 149 contigs\n",
      "   True tobamovirus palmprint hits: 40 contigs\n",
      "   Palmprint precision: 26.8% (40/149)\n",
      "   Palmprint recall vs ground truth: 17.5% (40/228)\n",
      "   Palmprint data structure needs investigation\n"
     ]
    }
   ],
   "source": [
    "# Method-specific Analysis and Performance Comparison\n",
    "\n",
    "print(\"\\n=== METHOD-SPECIFIC ANALYSIS ===\")\n",
    "\n",
    "# Check available columns first\n",
    "print(f\"\\nAvailable columns in datasets:\")\n",
    "print(f\"Ground Truth columns: {list(ground_truth.columns)}\")\n",
    "print(f\"DIAMOND/MEGAN columns: {list(diamond_megan_results.columns)}\")\n",
    "print(f\"Model predictions columns: {list(model_predictions.columns)}\")\n",
    "\n",
    "# 1. Manual Curation Analysis\n",
    "print(\"\\n1. ðŸ“‹ MANUAL CURATION (Ground Truth):\")\n",
    "print(f\"   Total samples: {len(ground_truth)}\")\n",
    "\n",
    "# Find family column (might be different case)\n",
    "family_col = None\n",
    "for col in ground_truth.columns:\n",
    "    if 'family' in col.lower():\n",
    "        family_col = col\n",
    "        break\n",
    "\n",
    "if family_col:\n",
    "    family_dist = ground_truth[family_col].value_counts()\n",
    "    print(f\"   Total families identified: {family_dist.nunique()}\")\n",
    "    print(f\"   Most common families:\")\n",
    "    for family, count in family_dist.head(5).items():\n",
    "        print(f\"   - {family}: {count} ({count/len(ground_truth)*100:.1f}%)\")\n",
    "        \n",
    "    # Check for tobamovirus\n",
    "    tobamo_mask = ground_truth[family_col].str.contains('Tobamovirus', case=False, na=False)\n",
    "    tobamo_count = tobamo_mask.sum()\n",
    "    print(f\"   Tobamovirus samples: {tobamo_count} ({tobamo_count/len(ground_truth)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"   No family column found in ground truth data\")\n",
    "\n",
    "# 2. DIAMOND/MEGAN Analysis\n",
    "print(\"\\n2. ðŸ’Ž DIAMOND/MEGAN Analysis:\")\n",
    "print(f\"   Total samples processed: {len(diamond_megan_results)}\")\n",
    "if 'megan_tobamo' in locals():\n",
    "    print(f\"   Tobamovirus-positive samples: {len(megan_tobamo)}\")\n",
    "    \n",
    "# 3. Machine Learning Model Analysis\n",
    "print(\"\\n3. ðŸ¤– MACHINE LEARNING MODEL:\")\n",
    "print(f\"   Total predictions: {len(model_predictions)}\")\n",
    "if 'model_tobamo' in locals():\n",
    "    print(f\"   Tobamovirus predictions: {len(model_tobamo)}\")\n",
    "    \n",
    "# Check for confidence/probability columns\n",
    "prob_cols = [col for col in model_predictions.columns if any(term in col.lower() for term in ['conf', 'prob', 'score'])]\n",
    "if prob_cols:\n",
    "    print(f\"   Confidence columns available: {prob_cols}\")\n",
    "\n",
    "# 4. Palmprint Analysis\n",
    "print(\"\\n4. ðŸ–¨ï¸ PALMPRINT Analysis:\")\n",
    "if 'palmprint_positive_contigs' in locals():\n",
    "    print(f\"   Total positive hits: {len(palmprint_positive_contigs)} contigs\")\n",
    "if 'tobamo_palmprints' in locals():\n",
    "    print(f\"   True tobamovirus palmprint hits: {len(tobamo_palmprints)} contigs\")\n",
    "    # Calculate precision (against all palmprint hits) and recall (against ground truth tobamo)\n",
    "    if 'palmprint_positive_contigs' in locals():\n",
    "        precision = len(tobamo_palmprints) / len(palmprint_positive_contigs) * 100 if len(palmprint_positive_contigs) > 0 else 0\n",
    "        print(f\"   Palmprint precision: {precision:.1f}% ({len(tobamo_palmprints)}/{len(palmprint_positive_contigs)})\")\n",
    "    \n",
    "    # Calculate recall against ground truth tobamo (228 total)\n",
    "    ground_truth_tobamo_count = 228  # df['ground_truth_category'].isin(['tob1','tob2','tob3']).sum()\n",
    "    recall = len(tobamo_palmprints) / ground_truth_tobamo_count * 100\n",
    "    print(f\"   Palmprint recall vs ground truth: {recall:.1f}% ({len(tobamo_palmprints)}/{ground_truth_tobamo_count})\")\n",
    "    \n",
    "if not any(var in locals() for var in ['palmprint_positive_contigs', 'tobamo_palmprints']):\n",
    "    print(\"   Palmprint data structure needs investigation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e859536f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CROSS-METHOD COMPARISON FOR TOBAMOVIRUS DETECTION ===\n",
      "\n",
      "ðŸŽ¯ GROUND TRUTH BASELINE:\n",
      "   Total tobamovirus samples: 228\n",
      "   Total samples: 510\n",
      "   Prevalence: 44.7%\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 1: Ground Truth Baseline\n",
    "\n",
    "print(\"\\n=== CROSS-METHOD COMPARISON FOR TOBAMOVIRUS DETECTION ===\")\n",
    "\n",
    "# Ground Truth Baseline\n",
    "ground_truth_tobamo_count = df['ground_truth_category'].isin(['tob1','tob2','tob3']).sum()\n",
    "print(f\"\\nðŸŽ¯ GROUND TRUTH BASELINE:\")\n",
    "print(f\"   Total tobamovirus samples: {ground_truth_tobamo_count}\")\n",
    "print(f\"   Total samples: {len(df)}\")\n",
    "print(f\"   Prevalence: {ground_truth_tobamo_count/len(df)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89b982d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š TOBAMOVIRUS DETECTION PERFORMANCE BY METHOD:\n",
      "\n",
      "1. ðŸ–¨ï¸  PALMPRINT METHOD:\n",
      "   Analyzing palmprint results...\n",
      "   True Positives: 40\n",
      "   Total Positives Detected: 149\n",
      "   Precision: 26.8% (40/149)\n",
      "   Recall (Sensitivity): 17.5% (40/228)\n",
      "   F1 Score: 21.2\n",
      "   âœ… Palmprint analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 2: Palmprint Method Analysis\n",
    "\n",
    "print(f\"\\nðŸ“Š TOBAMOVIRUS DETECTION PERFORMANCE BY METHOD:\")\n",
    "\n",
    "# Method 1: Palmprint\n",
    "print(f\"\\n1. ðŸ–¨ï¸  PALMPRINT METHOD:\")\n",
    "print(f\"   Analyzing palmprint results...\")\n",
    "\n",
    "palmprint_tp = len(tobamo_palmprints)  # True positives\n",
    "palmprint_total_pos = len(palmprint_positive_contigs)  # Total palmprint positives\n",
    "palmprint_precision = palmprint_tp / palmprint_total_pos * 100 if palmprint_total_pos > 0 else 0\n",
    "palmprint_recall = palmprint_tp / ground_truth_tobamo_count * 100\n",
    "palmprint_f1 = 2 * (palmprint_precision * palmprint_recall) / (palmprint_precision + palmprint_recall) if (palmprint_precision + palmprint_recall) > 0 else 0\n",
    "\n",
    "print(f\"   True Positives: {palmprint_tp}\")\n",
    "print(f\"   Total Positives Detected: {palmprint_total_pos}\")\n",
    "print(f\"   Precision: {palmprint_precision:.1f}% ({palmprint_tp}/{palmprint_total_pos})\")\n",
    "print(f\"   Recall (Sensitivity): {palmprint_recall:.1f}% ({palmprint_tp}/{ground_truth_tobamo_count})\")\n",
    "print(f\"   F1 Score: {palmprint_f1:.1f}\")\n",
    "\n",
    "print(\"   âœ… Palmprint analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23497e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. ðŸ’Ž DIAMOND BLASTX:\n",
      "   Analyzing DIAMOND results...\n",
      "   Calculating total positives detected...\n",
      "   True Positives: 186\n",
      "   Total Positives Detected: 205\n",
      "   Precision: 90.7% (186/205)\n",
      "   Recall (Sensitivity): 81.6% (186/228)\n",
      "   F1 Score: 85.9\n",
      "   âœ… DIAMOND analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 3: DIAMOND BLASTX Analysis\n",
    "\n",
    "# Method 2: DIAMOND BLASTX\n",
    "print(f\"\\n2. ðŸ’Ž DIAMOND BLASTX:\")\n",
    "print(f\"   Analyzing DIAMOND results...\")\n",
    "\n",
    "diamond_tp = len(nt_tobamo)\n",
    "print(f\"   Calculating total positives detected...\")\n",
    "diamond_total_pos = df['first_diamond_blastx_hit_name'].str.contains('tobamovirus', case=False, na=False).sum()\n",
    "diamond_precision = diamond_tp / diamond_total_pos * 100 if diamond_total_pos > 0 else 0\n",
    "diamond_recall = diamond_tp / ground_truth_tobamo_count * 100\n",
    "diamond_f1 = 2 * (diamond_precision * diamond_recall) / (diamond_precision + diamond_recall) if (diamond_precision + diamond_recall) > 0 else 0\n",
    "\n",
    "print(f\"   True Positives: {diamond_tp}\")\n",
    "print(f\"   Total Positives Detected: {diamond_total_pos}\")\n",
    "print(f\"   Precision: {diamond_precision:.1f}% ({diamond_tp}/{diamond_total_pos})\")\n",
    "print(f\"   Recall (Sensitivity): {diamond_recall:.1f}% ({diamond_tp}/{ground_truth_tobamo_count})\")\n",
    "print(f\"   F1 Score: {diamond_f1:.1f}\")\n",
    "\n",
    "print(\"   âœ… DIAMOND analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4848694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ðŸ§¬ MEGAN6 LCA:\n",
      "   Analyzing MEGAN6 results...\n",
      "   Calculating MEGAN6 positives...\n",
      "   True Positives: 202\n",
      "   Total Positives Detected: 215\n",
      "   Precision: 94.0% (202/215)\n",
      "   Recall (Sensitivity): 88.6% (202/228)\n",
      "   F1 Score: 91.2\n",
      "   âœ… MEGAN6 analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 4: MEGAN6 Analysis\n",
    "\n",
    "# Method 3: MEGAN6\n",
    "print(f\"\\n3. ðŸ§¬ MEGAN6 LCA:\")\n",
    "print(f\"   Analyzing MEGAN6 results...\")\n",
    "\n",
    "megan_tp = len(megan_tobamo)\n",
    "print(f\"   Calculating MEGAN6 positives...\")\n",
    "megan_total_pos = df['megan_tax'].str.contains('tobamovirus', case=False, na=False).sum()\n",
    "megan_precision = megan_tp / megan_total_pos * 100 if megan_total_pos > 0 else 0\n",
    "megan_recall = megan_tp / ground_truth_tobamo_count * 100\n",
    "megan_f1 = 2 * (megan_precision * megan_recall) / (megan_precision + megan_recall) if (megan_precision + megan_recall) > 0 else 0\n",
    "\n",
    "print(f\"   True Positives: {megan_tp}\")\n",
    "print(f\"   Total Positives Detected: {megan_total_pos}\")\n",
    "print(f\"   Precision: {megan_precision:.1f}% ({megan_tp}/{megan_total_pos})\")\n",
    "print(f\"   Recall (Sensitivity): {megan_recall:.1f}% ({megan_tp}/{ground_truth_tobamo_count})\")\n",
    "print(f\"   F1 Score: {megan_f1:.1f}\")\n",
    "\n",
    "print(\"   âœ… MEGAN6 analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95b2f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. ðŸ¤– MACHINE LEARNING MODEL:\n",
      "   Analyzing ML model results...\n",
      "   Calculating ML predictions...\n",
      "   True Positives: 212\n",
      "   Total Positives Detected: 285\n",
      "   Precision: 74.4% (212/285)\n",
      "   Recall (Sensitivity): 93.0% (212/228)\n",
      "   F1 Score: 82.7\n",
      "   âœ… ML Model analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 5: Machine Learning Model Analysis\n",
    "\n",
    "# Method 4: Machine Learning Model\n",
    "print(f\"\\n4. ðŸ¤– MACHINE LEARNING MODEL:\")\n",
    "print(f\"   Analyzing ML model results...\")\n",
    "\n",
    "ml_tp = len(model_tobamo)\n",
    "print(f\"   Calculating ML predictions...\")\n",
    "ml_total_pos = (df['model_prediction'] == 1).sum()\n",
    "ml_precision = ml_tp / ml_total_pos * 100 if ml_total_pos > 0 else 0\n",
    "ml_recall = ml_tp / ground_truth_tobamo_count * 100\n",
    "ml_f1 = 2 * (ml_precision * ml_recall) / (ml_precision + ml_recall) if (ml_precision + ml_recall) > 0 else 0\n",
    "\n",
    "print(f\"   True Positives: {ml_tp}\")\n",
    "print(f\"   Total Positives Detected: {ml_total_pos}\")\n",
    "print(f\"   Precision: {ml_precision:.1f}% ({ml_tp}/{ml_total_pos})\")\n",
    "print(f\"   Recall (Sensitivity): {ml_recall:.1f}% ({ml_tp}/{ground_truth_tobamo_count})\")\n",
    "print(f\"   F1 Score: {ml_f1:.1f}\")\n",
    "\n",
    "print(\"   âœ… ML Model analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "857076c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† PERFORMANCE RANKING:\n",
      "ðŸ“ˆ RECALL (Sensitivity) - How many true tobamoviruses detected:\n",
      "   1. ML Model: 93.0%\n",
      "   2. MEGAN6: 88.6%\n",
      "   3. DIAMOND: 81.6%\n",
      "   4. Palmprint: 17.5%\n",
      "\n",
      "ðŸŽ¯ PRECISION - Accuracy of positive predictions:\n",
      "   1. MEGAN6: 94.0%\n",
      "   2. DIAMOND: 90.7%\n",
      "   3. ML Model: 74.4%\n",
      "   4. Palmprint: 26.8%\n",
      "\n",
      "âš–ï¸  F1 SCORE - Balanced performance:\n",
      "   1. MEGAN6: 91.2\n",
      "   2. DIAMOND: 85.9\n",
      "   3. ML Model: 82.7\n",
      "   4. Palmprint: 21.2\n",
      "   âœ… Performance ranking completed\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 6: Performance Rankings\n",
    "\n",
    "print(f\"\\nðŸ† PERFORMANCE RANKING:\")\n",
    "print(f\"ðŸ“ˆ RECALL (Sensitivity) - How many true tobamoviruses detected:\")\n",
    "methods_recall = [\n",
    "    (\"Palmprint\", palmprint_recall),\n",
    "    (\"DIAMOND\", diamond_recall),\n",
    "    (\"MEGAN6\", megan_recall),\n",
    "    (\"ML Model\", ml_recall)\n",
    "]\n",
    "methods_recall.sort(key=lambda x: x[1], reverse=True)\n",
    "for i, (method, recall) in enumerate(methods_recall, 1):\n",
    "    print(f\"   {i}. {method}: {recall:.1f}%\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ PRECISION - Accuracy of positive predictions:\")\n",
    "methods_precision = [\n",
    "    (\"Palmprint\", palmprint_precision),\n",
    "    (\"DIAMOND\", diamond_precision),\n",
    "    (\"MEGAN6\", megan_precision),\n",
    "    (\"ML Model\", ml_precision)\n",
    "]\n",
    "methods_precision.sort(key=lambda x: x[1], reverse=True)\n",
    "for i, (method, precision) in enumerate(methods_precision, 1):\n",
    "    print(f\"   {i}. {method}: {precision:.1f}%\")\n",
    "\n",
    "print(f\"\\nâš–ï¸  F1 SCORE - Balanced performance:\")\n",
    "methods_f1 = [\n",
    "    (\"Palmprint\", palmprint_f1),\n",
    "    (\"DIAMOND\", diamond_f1),\n",
    "    (\"MEGAN6\", megan_f1),\n",
    "    (\"ML Model\", ml_f1)\n",
    "]\n",
    "methods_f1.sort(key=lambda x: x[1], reverse=True)\n",
    "for i, (method, f1) in enumerate(methods_f1, 1):\n",
    "    print(f\"   {i}. {method}: {f1:.1f}\")\n",
    "\n",
    "print(\"   âœ… Performance ranking completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dff3b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” METHOD CHARACTERISTICS SUMMARY:\n",
      "â€¢ DIAMOND: High precision (90.7%), moderate recall (81.6%) - Conservative approach\n",
      "â€¢ MEGAN6: High precision (94.0%), moderate recall (88.6%) - LCA consensus\n",
      "â€¢ ML Model: Balanced precision (74.4%) and recall (93.0%) - Data-driven\n",
      "â€¢ Palmprint: Variable performance - Novel method needing validation\n",
      "   âœ… Method characteristics summary completed\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 7: Method Characteristics Summary\n",
    "\n",
    "print(f\"\\nðŸ” METHOD CHARACTERISTICS SUMMARY:\")\n",
    "print(f\"â€¢ DIAMOND: High precision ({diamond_precision:.1f}%), moderate recall ({diamond_recall:.1f}%) - Conservative approach\")\n",
    "print(f\"â€¢ MEGAN6: High precision ({megan_precision:.1f}%), moderate recall ({megan_recall:.1f}%) - LCA consensus\")\n",
    "print(f\"â€¢ ML Model: Balanced precision ({ml_precision:.1f}%) and recall ({ml_recall:.1f}%) - Data-driven\")\n",
    "print(f\"â€¢ Palmprint: Variable performance - Novel method needing validation\")\n",
    "\n",
    "print(\"   âœ… Method characteristics summary completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4376598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ­ METHOD OVERLAP ANALYSIS:\n",
      "   Building contig sets for overlap analysis...\n",
      "   Palmprint set: 40 contigs\n",
      "   DIAMOND set: 186 contigs\n",
      "   MEGAN6 set: 202 contigs\n",
      "   ML Model set: 212 contigs\n",
      "   âœ… Contig sets created successfully\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 8: Method Overlap Analysis (Potentially Slow)\n",
    "\n",
    "# Calculate overall detection overlap\n",
    "print(f\"\\nðŸŽ­ METHOD OVERLAP ANALYSIS:\")\n",
    "print(\"   Building contig sets for overlap analysis...\")\n",
    "\n",
    "# Create sets of detected contigs for each method\n",
    "palmprint_set = set(tobamo_palmprints['contig_id'])\n",
    "print(f\"   Palmprint set: {len(palmprint_set)} contigs\")\n",
    "\n",
    "diamond_set = set(nt_tobamo['contig_id'])\n",
    "print(f\"   DIAMOND set: {len(diamond_set)} contigs\")\n",
    "\n",
    "megan_set = set(megan_tobamo['contig_id'])\n",
    "print(f\"   MEGAN6 set: {len(megan_set)} contigs\")\n",
    "\n",
    "ml_set = set(model_tobamo['contig_id'])\n",
    "print(f\"   ML Model set: {len(ml_set)} contigs\")\n",
    "\n",
    "print(\"   âœ… Contig sets created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14dee832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ CALCULATING SET INTERSECTIONS:\n",
      "   Computing intersection of all methods...\n",
      "   All methods intersection: 27 contigs\n",
      "   Computing union of all methods...\n",
      "   Any method union: 228 contigs\n",
      "   Computing consensus (â‰¥3 methods)...\n",
      "   Detected by all 4 methods: 27 contigs\n",
      "   Detected by â‰¥3 methods: 170 contigs\n",
      "   Detected by any method: 228 contigs\n",
      "   Consensus confidence: 11.8% agreement\n",
      "   âœ… Cross-method comparison analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cross-Method Comparison - Part 9: Set Intersection Analysis\n",
    "\n",
    "print(f\"\\nðŸ”„ CALCULATING SET INTERSECTIONS:\")\n",
    "\n",
    "# Intersection analysis\n",
    "print(\"   Computing intersection of all methods...\")\n",
    "all_methods = palmprint_set.intersection(diamond_set).intersection(megan_set).intersection(ml_set)\n",
    "print(f\"   All methods intersection: {len(all_methods)} contigs\")\n",
    "\n",
    "print(\"   Computing union of all methods...\")\n",
    "any_method = palmprint_set.union(diamond_set).union(megan_set).union(ml_set)\n",
    "print(f\"   Any method union: {len(any_method)} contigs\")\n",
    "\n",
    "print(\"   Computing consensus (â‰¥3 methods)...\")\n",
    "consensus_3_plus = len([contig for contig in any_method \n",
    "                       if sum([contig in s for s in [palmprint_set, diamond_set, megan_set, ml_set]]) >= 3])\n",
    "\n",
    "print(f\"   Detected by all 4 methods: {len(all_methods)} contigs\")\n",
    "print(f\"   Detected by â‰¥3 methods: {consensus_3_plus} contigs\")\n",
    "print(f\"   Detected by any method: {len(any_method)} contigs\")\n",
    "print(f\"   Consensus confidence: {len(all_methods)/len(any_method)*100:.1f}% agreement\")\n",
    "\n",
    "print(\"   âœ… Cross-method comparison analysis completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobamo-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
